{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN implementation based off of the model from https://www.kaggle.com/code/mrhippo/audio-generation-with-simple-gans/notebook#Bulding-GANs-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science and mathematical operations\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import IPython\n",
    "import IPython.display as ipd \n",
    "import glob\n",
    "import random\n",
    "\n",
    "# deep learning\n",
    "from keras.layers import Dense, Dropout, Input, ReLU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Config\n",
    "DURATION = 4\n",
    "SAMPLE_RATE = 16000\n",
    "AUDIO_SHAPE = SAMPLE_RATE*DURATION\n",
    "\n",
    "#MFCC = 40\n",
    "\n",
    "# Paths\n",
    "#DATASET_PATH = \"/ccdata/*/*.wav\"\n",
    "\n",
    "# Load \n",
    "def load_train_data(input_length=AUDIO_SHAPE):\n",
    "    files = glob.glob(\"/Users/ryanzrymiak/Downloads/ccdata/*/*.wav\")\n",
    "    print(files)\n",
    "    X = np.empty((len(files), input_length))\n",
    "    i = 0\n",
    "    #audio_samples = []\n",
    "    for file_path in glob.glob(\"/Users/ryanzrymiak/Downloads/ccdata/*/*.wav\"):\n",
    "        #file_path = DATASET_PATH + \"audio_train/\" + train_fname\n",
    "        \n",
    "        # Read and Resample the audio\n",
    "        audio, _ = librosa.core.load(file_path, sr=SAMPLE_RATE)#, res_type='kaiser_fast')\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(audio) > input_length:\n",
    "            max_offset = len(audio) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            audio = audio[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(audio):\n",
    "                max_offset = input_length - len(audio)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            audio = np.pad(audio, (offset, input_length - len(audio) - offset), \"constant\")\n",
    "        X[i,] = audio\n",
    "        #audio_samples.append(audio)\n",
    "        i+=1\n",
    "    print(\"Data loading complete\")\n",
    "    return X#audio_samples\n",
    "\n",
    "# Stardize Data \n",
    "def normalization(sample):\n",
    "    #for i in range(0,len(sample)):\n",
    "    sample = (sample - sample.mean()) / sample.std()\n",
    "    print(\"Normalization complete\\n\")\n",
    "    return sample\n",
    "\n",
    "# Rescale Data to be in range [rangeMin, rangeMax]\n",
    "def rescale(sample):\n",
    "    #minRange=-1\n",
    "    #maxRange=1\n",
    "    #maxi = sample.max()\n",
    "    #mini = sample.min()\n",
    "    #sample = np.interp(sample, (mini, maxi), (minRange, maxRange))\n",
    "    #for i in range(0,len(sample)):\n",
    "    sample /= np.max(np.abs(sample), axis=0)\n",
    "    print(\"Rescaling complete\\n\")\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalization(load_train_data(AUDIO_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = rescale(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    \n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(units = 512, input_dim = 100))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 512))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 1024))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 1024))\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    generator.add(Dense(units = 64000))\n",
    "    \n",
    "    generator.compile(loss =\"binary_crossentropy\",\n",
    "                     optimizer = Adam(0.0001, 0.5))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "#g = create_generator()\n",
    "#g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(units = 1024,input_dim = 64000)) \n",
    "    discriminator.add(ReLU())\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "    discriminator.add(Dense(units = 512)) \n",
    "    discriminator.add(ReLU())\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "    discriminator.add(Dense(units = 256)) \n",
    "    discriminator.add(ReLU())\n",
    "    \n",
    "    discriminator.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "    \n",
    "    discriminator.compile(loss = \"binary_crossentropy\",\n",
    "                         optimizer = Adam(0.0001, 0.5))\n",
    "    return discriminator\n",
    "\n",
    "#d = create_discriminator()\n",
    "#d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs = gan_input, outputs = gan_output)\n",
    "    gan.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")\n",
    "    return gan\n",
    "\n",
    "#gan = create_gan(d,g)\n",
    "#gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gen_samples(epochs):#, samples = 3):\n",
    "    samplePlot = []\n",
    "    #fig        = plt.figure(figsize = (1, samples))\n",
    "    #noise      = np.random.normal(0, 1, (samples,100))\n",
    "    audios     = g.predict(noise)    \n",
    "    #for i, audio in enumerate(audios):\n",
    "    for i in range(0, 3):\n",
    "        #print(audio)\n",
    "        IPython.display.display(ipd.Audio(data = random.choice(audios), rate = SAMPLE_RATE))\n",
    "    #    samplePlot.append(fig.add_subplot(1, samples, i+1))\n",
    "    #    samplePlot[i].plot(audio.flatten(), '-', )\n",
    "    #plt.gcf().set_size_inches(25, 5)\n",
    "    #plt.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    #fig.suptitle(\"{} Epochs Result\".format(epochs), fontsize = 17)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "epochs = 40 \n",
    "batch_size = 128\n",
    "#current_time = time.time()\n",
    "\n",
    "g = create_generator()\n",
    "g.summary()\n",
    "\n",
    "d = create_discriminator()\n",
    "d.summary()\n",
    "\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()\n",
    "\n",
    "for e in range(epochs):\n",
    "    #start_time = time.time()\n",
    "    #for _ in range(batch_size):\n",
    "        #print(e, \"--\", _)\n",
    "        # I reccomend you to look \"Training Diagram\" (at the top) \n",
    "        noise = np.random.normal(0,1, [batch_size,100])\n",
    "        \n",
    "        generated_audio = g.predict(noise)\n",
    "       \n",
    "        audio_batch = x_train[np.random.randint(low = 0, high = x_train.shape[0], size = batch_size)] #get samples from real data\n",
    "\n",
    "        x = np.concatenate([audio_batch, generated_audio])\n",
    "\n",
    "        y_dis = np.zeros(batch_size*2) \n",
    "        y_dis[:batch_size] = 1 # we labeled real audios as 1 and generated audios as 0\n",
    "        \n",
    "        d.trainable = True\n",
    "        d_loss = d.train_on_batch(x,y_dis) # we are training discriminator (train_on_batch)\n",
    "        \n",
    "        noise = np.random.normal(0,1,[batch_size,100])\n",
    "        \n",
    "        y_gen = np.ones(batch_size) # our generator says \"these audios are real\"\n",
    "        \n",
    "        d.trainable = False\n",
    "        \n",
    "        g_loss = gan.train_on_batch(noise, y_gen) #train_on_batch\n",
    "        \n",
    "        #D_loss.append(d_loss)\n",
    "        #G_loss.append(g_loss)\n",
    "        \n",
    "    #if (e%2 == 0) or (e == epochs-1) :\n",
    "    #    print(\"epochs: \",e)\n",
    "    #if e == epochs-1:\n",
    "    #    print(\"Time since start: {}\".format(np.round(start_time - current_time)))\n",
    "    #    print(\"Training Complete.\")\n",
    "    # printing results\n",
    "        if e%10 == 0:\n",
    "        #print(\"Time since start: {}\".format(np.round(start_time - current_time)))\n",
    "            show_gen_samples(e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
